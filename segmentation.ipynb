{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7539076,"sourceType":"datasetVersion","datasetId":4238001},{"sourceId":7767309,"sourceType":"datasetVersion","datasetId":4351993}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Imports & Constants\n\nHere we just define some imports and select some test images to see later how well our models perform.","metadata":{}},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport numpy as np\nimport tensorflow as tf\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.utils import image_dataset_from_directory\n\n# For reproducability\ntf.random.set_seed(0)\ntf.config.experimental.enable_op_determinism()\n\n# For classification, any dataset works under anylgasses (face-attributes-grouped is just example)\nCLS_DATA_ROOT = \"/kaggle/input/glasses-detector/classification/anyglasses/face-attributes-grouped/\"\nSEG_DATA_ROOT = \"/kaggle/input/face-synthetics-glasses/face-synthetics-glasses/\"\nAUTOTUNE = tf.data.AUTOTUNE\n\n# Classification test paths\nTEST_IMG_PATHS_CLS = [\n    os.path.join(CLS_DATA_ROOT, \"test/no_anyglasses/0f57d9216de31fd27dcac57c61a61019.jpg\"),\n    os.path.join(CLS_DATA_ROOT, \"test/anyglasses/4.jpg\"),\n    os.path.join(CLS_DATA_ROOT, \"test/no_anyglasses/000031c9.jpg\"),\n    os.path.join(CLS_DATA_ROOT, \"test/anyglasses/54ca1e397e9f765801ccbbf33f41c808.jpg\"),\n    os.path.join(CLS_DATA_ROOT, \"test/no_anyglasses/1438659549.jpg\"),\n]\n\n# Segmentation test paths\nTEST_IMG_PATHS_SEG = [\n    os.path.join(SEG_DATA_ROOT, \"test/images/000410.jpg\"),\n    os.path.join(SEG_DATA_ROOT, \"test/images/000664.jpg\"),\n    os.path.join(SEG_DATA_ROOT, \"test/images/001034.jpg\"),\n    os.path.join(SEG_DATA_ROOT, \"test/images/000987.jpg\"),\n    os.path.join(SEG_DATA_ROOT, \"test/images/001421.jpg\"),\n]","metadata":{"execution":{"iopub.status.busy":"2024-04-01T15:41:22.724019Z","iopub.execute_input":"2024-04-01T15:41:22.724945Z","iopub.status.idle":"2024-04-01T15:41:35.512096Z","shell.execute_reply.started":"2024-04-01T15:41:22.724897Z","shell.execute_reply":"2024-04-01T15:41:35.511123Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-04-01 15:41:24.468510: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-01 15:41:24.468668: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-01 15:41:24.602493: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Utilities\n\nHere we define a custom **F1Score** metric which passes the predictions through sigmoid first, two custom methods for loading classification and segmentation data and a method for displaying classifier or segmenter predictions.","metadata":{}},{"cell_type":"code","source":"class SigmoidF1Score(tf.keras.metrics.F1Score):\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        # Flatten across batch; squeeze preds to [0, 1]\n        shape = (-1, tf.shape(y_true)[-1])\n        y_true = tf.reshape(y_true, shape)\n        y_pred = tf.reshape(y_pred, shape)\n        y_pred = tf.nn.sigmoid(y_pred)\n\n        return super().update_state(y_true, y_pred, sample_weight)\n\ndef create_dataset_cls(split):\n    # Load the dataset from directory\n    ds = image_dataset_from_directory(\n        directory=os.path.join(CLS_DATA_ROOT, split),\n        label_mode=\"binary\",\n        shuffle=split==\"train\",\n        seed=0,\n    )\n    class_names = ds.class_names\n    \n    # Specify buffer size and image rescaling\n    ds = ds.cache().prefetch(buffer_size=AUTOTUNE)\n    ds = ds.map(lambda x, y: (layers.Rescaling(1./255)(x), y))\n    ds.class_names = class_names\n    \n    return ds\n\ndef create_dataset_seg(split):\n    # Load the image dataset from directory\n    ds_img = image_dataset_from_directory(\n        directory=os.path.join(SEG_DATA_ROOT, split, \"images\"),\n        label_mode=None,\n        shuffle=split==\"train\",\n        seed=0,\n    )\n    \n    # Load the mask dataset from directory\n    ds_msk = image_dataset_from_directory(\n        directory=os.path.join(SEG_DATA_ROOT, split, \"masks\"),\n        label_mode=None,\n        color_mode=\"grayscale\",\n        shuffle=split==\"train\",\n        seed=0,\n    )\n    \n    # Join and specify buffer and rescaling\n    ds = tf.data.Dataset.zip((ds_img, ds_msk))\n    ds = ds.map(lambda x, y: (layers.Rescaling(1./255)(x), tf.where(y > 127, 1., 0.)))\n\n    return ds\n\ndef display_predictions(ds, model, task, num_images=5, seed=0):\n    \n    if task == \"classification\":\n        # If the task is classification\n        img_paths = TEST_IMG_PATHS_CLS\n    elif task == \"segmentation\":\n        # If the task is segmentation\n        img_paths = TEST_IMG_PATHS_SEG\n    \n    # Load images from paths\n    images = np.array([\n        tf.keras.utils.img_to_array(tf.keras.utils.load_img(img_path))\n        for img_path in img_paths\n    ])\n    \n    # Predict with model & initialize plot\n    predictions = model.predict((1/255) * images)\n    plt.figure(figsize=(20, 4))\n    \n    for i in range(num_images):\n        # Plot the input image in ith column\n        ax = plt.subplot(1, num_images, i + 1)\n        plt.imshow(images[i].astype(\"uint8\"))\n        plt.axis(\"off\")\n        \n        if task == \"classification\":\n            # Display the prediction as an image title\n            plt.title(ds.class_names[int(predictions[i][0] > 0)])\n        elif task == \"segmentation\":\n            # Display the prediction as overlaid image\n            colors = [(0, 0, 0, 0)] + [(1, 0, 0, 1)] * 255\n            cm = mcolors.LinearSegmentedColormap.from_list(\"red\", colors, N=256)\n            plt.imshow(1 * (predictions[i].squeeze() > 0), alpha=0.5, cmap=cm, vmin=0, vmax=1)\n    \n    # Show preds\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-01T15:41:55.283586Z","iopub.execute_input":"2024-04-01T15:41:55.284536Z","iopub.status.idle":"2024-04-01T15:41:55.302163Z","shell.execute_reply.started":"2024-04-01T15:41:55.284493Z","shell.execute_reply":"2024-04-01T15:41:55.301183Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Classification\n\nWe define a simple classifier, train for 5 epochs, and see the results.","metadata":{}},{"cell_type":"markdown","source":"## Segmentation\n\nWe define a simple segmenter, train for 5 epochs, and see the results (could be better if the model was more complex).","metadata":{}},{"cell_type":"code","source":"# Generate datasets from image directories\nds_seg_train = create_dataset_seg(\"train\")\nds_seg_val = create_dataset_seg(\"val\")\n\n# Very simple segmenter\nsegmenter = Sequential([\n    layers.Conv2D(50, 3, padding=\"same\", activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Conv2D(100, 3, padding=\"same\", activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Conv2D(150, 3, padding=\"same\", activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Conv2D(100, 3, padding=\"same\", activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Conv2D(50, 3, padding=\"same\"),\n    layers.BatchNormalization(),\n    layers.Conv2D(1, 1),\n])\n\n# Compile with AdamW\nsegmenter.compile(\n    optimizer=tf.keras.optimizers.AdamW(learning_rate=0.0001),\n    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[SigmoidF1Score(average=\"micro\", threshold=.5, name=\"dice\")],\n)\n\n# Fit the model and show some predictions from selected test images\nsegmenter.fit(ds_seg_train, validation_data=ds_seg_val, epochs=5)\ndisplay_predictions(ds_cls_val, segmenter, task=\"segmentation\")","metadata":{"execution":{"iopub.status.busy":"2024-04-01T15:42:11.165592Z","iopub.execute_input":"2024-04-01T15:42:11.166318Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Found 11372 files belonging to 1 classes.\nFound 11372 files belonging to 1 classes.\nFound 1481 files belonging to 1 classes.\nFound 1481 files belonging to 1 classes.\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1711986183.265100     114 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"168/356 [=============>................] - ETA: 1:48 - loss: 0.6501 - dice: 0.2187","output_type":"stream"}]}]}